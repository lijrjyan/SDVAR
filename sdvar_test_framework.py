#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SDVARå¹¶è¡ŒéªŒè¯ v1.0 æµ‹è¯•æ¡†æ¶
ç”¨äºéªŒè¯ä¿®å¤è¿‡ç¨‹ä¸­çš„æ¯ä¸ªæ­¥éª¤
"""

# ç¯å¢ƒæ£€æŸ¥
def check_environment():
    """æ£€æŸ¥è¿è¡Œç¯å¢ƒ"""
    try:
        import torch
        import numpy as np
        return True, "ç¯å¢ƒæ£€æŸ¥é€šè¿‡"
    except ImportError as e:
        return False, f"ç¯å¢ƒæ£€æŸ¥å¤±è´¥: {str(e)}"

from typing import List, Tuple, Optional, Dict, Any
import time
import traceback
from dataclasses import dataclass


@dataclass
class TestResult:
    """æµ‹è¯•ç»“æœæ•°æ®ç±»"""
    test_name: str
    passed: bool
    message: str
    details: Optional[Dict[str, Any]] = None
    execution_time: float = 0.0


class SDVARTestFramework:
    """SDVARæµ‹è¯•æ¡†æ¶ - ä¸“é—¨ç”¨äºéªŒè¯parallel_v1å‡½æ•°"""
    
    def __init__(self, verbose: bool = True):
        self.verbose = verbose
        self.test_results = []
        
    def log(self, message: str, level: str = "INFO"):
        """ç»Ÿä¸€æ—¥å¿—è¾“å‡º"""
        if self.verbose:
            prefix = f"[{level}]" if level else ""
            print(f"{prefix} {message}")
            
    def run_test(self, test_func, test_name: str, *args, **kwargs) -> TestResult:
        """è¿è¡Œå•ä¸ªæµ‹è¯•"""
        self.log(f"ğŸ§ª è¿è¡Œæµ‹è¯•: {test_name}")
        
        start_time = time.time()
        try:
            result = test_func(*args, **kwargs)
            execution_time = time.time() - start_time
            
            if isinstance(result, bool):
                passed = result
                message = "æµ‹è¯•é€šè¿‡" if passed else "æµ‹è¯•å¤±è´¥"
                details = None
            elif isinstance(result, tuple) and len(result) >= 2:
                passed, message = result[:2]
                details = result[2] if len(result) > 2 else None
            else:
                passed = True
                message = str(result)
                details = None
                
            test_result = TestResult(
                test_name=test_name,
                passed=passed,
                message=message,
                details=details,
                execution_time=execution_time
            )
            
            self.test_results.append(test_result)
            status = "âœ…" if passed else "âŒ"
            self.log(f"{status} {test_name}: {message} ({execution_time:.3f}s)")
            
            return test_result
            
        except Exception as e:
            execution_time = time.time() - start_time
            test_result = TestResult(
                test_name=test_name,
                passed=False,
                message=f"å¼‚å¸¸: {str(e)}",
                details={"traceback": traceback.format_exc()},
                execution_time=execution_time
            )
            
            self.test_results.append(test_result)
            self.log(f"âŒ {test_name}: å¼‚å¸¸ - {str(e)}")
            
            return test_result

    def print_summary(self):
        """æ‰“å°æµ‹è¯•æ‘˜è¦"""
        total_tests = len(self.test_results)
        passed_tests = sum(1 for r in self.test_results if r.passed)
        
        print("\n" + "="*60)
        print(f"ğŸ“Š æµ‹è¯•æ‘˜è¦: {passed_tests}/{total_tests} é€šè¿‡")
        print("="*60)
        
        for result in self.test_results:
            status = "âœ…" if result.passed else "âŒ"
            print(f"{status} {result.test_name}: {result.message}")
            
        if passed_tests == total_tests:
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        else:
            print("âš ï¸  æœ‰æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥è¯¦ç»†ä¿¡æ¯")


class SDVARParallelV1Tester:
    """SDVAR parallel_v1 ä¸“ç”¨æµ‹è¯•ç±»"""
    
    def __init__(self, sdvar_model=None):
        self.sdvar_model = sdvar_model
        self.test_framework = SDVARTestFramework()
        
    def test_environment_check(self) -> Tuple[bool, str, Dict[str, Any]]:
        """æµ‹è¯•ç¯å¢ƒæ£€æŸ¥"""
        env_ok, env_msg = check_environment()
        return env_ok, env_msg, {"environment": env_ok}
        
    def test_state_initialization(self, B: int = 2, gamma: int = 2) -> Tuple[bool, str, Dict[str, Any]]:
        """æµ‹è¯•çŠ¶æ€åˆå§‹åŒ–"""
        try:
            if self.sdvar_model is None:
                return False, "SDVARæ¨¡å‹æœªåˆå§‹åŒ–", {}
                
            env_ok, _ = check_environment()
            if not env_ok:
                return False, "ç¯å¢ƒæ£€æŸ¥å¤±è´¥", {}
                
            # æ¨¡æ‹ŸçŠ¶æ€åˆå§‹åŒ–
            state = self.sdvar_model._initialize_inference_state(
                B=B, label_B=None, g_seed=42, cfg=1.5, gamma=gamma
            )
            
            # éªŒè¯å…³é”®å±æ€§
            checks = {
                "current_stage": state.current_stage == 0,
                "gamma": state.gamma == gamma,
                "total_stages": state.total_stages == 10,
                "patch_nums": len(state.patch_nums) == 10,
                "draft_f_hat_shape": state.draft_f_hat.shape == (B, 32, 16, 16),
                "target_f_hat_shape": state.target_f_hat.shape == (B, 32, 16, 16),
            }
            
            failed_checks = [k for k, v in checks.items() if not v]
            
            if failed_checks:
                return False, f"æ£€æŸ¥å¤±è´¥: {failed_checks}", checks
            else:
                return True, "çŠ¶æ€åˆå§‹åŒ–æ­£ç¡®", checks
                
        except Exception as e:
            return False, f"åˆå§‹åŒ–å¼‚å¸¸: {str(e)}", {}
    
    def test_draft_generate_batch(self, B: int = 2, gamma: int = 2) -> Tuple[bool, str, Dict[str, Any]]:
        """æµ‹è¯•draftæ‰¹é‡ç”Ÿæˆ"""
        try:
            if self.sdvar_model is None:
                return False, "SDVARæ¨¡å‹æœªåˆå§‹åŒ–", {}
                
            env_ok, _ = check_environment()
            if not env_ok:
                return False, "ç¯å¢ƒæ£€æŸ¥å¤±è´¥", {}
                
            # éœ€è¦å¯¼å…¥torchæ¥åˆ›å»ºtensor
            import torch
            
            # åˆå§‹åŒ–çŠ¶æ€
            state = self.sdvar_model._initialize_inference_state(
                B=B, label_B=torch.tensor([980, 437]), g_seed=42, cfg=1.5, gamma=gamma
            )
            
            # è°ƒç”¨draftç”Ÿæˆ
            draft_tokens = self.sdvar_model.draft_generate_batch(state, B, verbose=False)
            
            # éªŒè¯ç»“æœ
            checks = {
                "è¿”å›åˆ—è¡¨": isinstance(draft_tokens, list),
                "é•¿åº¦æ­£ç¡®": len(draft_tokens) <= gamma,
                "tokenå½¢çŠ¶": all(isinstance(t, torch.Tensor) for t in draft_tokens),
            }
            
            if draft_tokens:
                first_token = draft_tokens[0]
                pn = state.patch_nums[0]
                checks["é¦–ä¸ªtokenå½¢çŠ¶"] = first_token.shape == (B, pn * pn)
                
            failed_checks = [k for k, v in checks.items() if not v]
            
            if failed_checks:
                return False, f"æ£€æŸ¥å¤±è´¥: {failed_checks}", checks
            else:
                return True, f"ç”Ÿæˆ{len(draft_tokens)}ä¸ªstageçš„tokens", checks
                
        except Exception as e:
            return False, f"ç”Ÿæˆå¼‚å¸¸: {str(e)}", {}
    
    def test_build_combined_query(self, B: int = 2, gamma: int = 2) -> Tuple[bool, str, Dict[str, Any]]:
        """æµ‹è¯•combined queryæ„å»º"""
        try:
            if self.sdvar_model is None:
                return False, "SDVARæ¨¡å‹æœªåˆå§‹åŒ–", {}
                
            env_ok, _ = check_environment()
            if not env_ok:
                return False, "ç¯å¢ƒæ£€æŸ¥å¤±è´¥", {}
                
            import torch
            
            # åˆ›å»ºæ¨¡æ‹Ÿçš„draft tokens
            state = self.sdvar_model._initialize_inference_state(
                B=B, label_B=torch.tensor([980, 437]), g_seed=42, cfg=1.5, gamma=gamma
            )
            
            # ç”Ÿæˆæµ‹è¯•ç”¨çš„draft tokens
            draft_tokens = []
            for i in range(gamma):
                stage_idx = state.current_stage + i
                if stage_idx >= len(state.patch_nums):
                    break
                pn = state.patch_nums[stage_idx]
                # åˆ›å»ºéšæœºtokens
                tokens = torch.randint(0, 4096, (B, pn * pn), device=state.draft_f_hat.device)
                draft_tokens.append(tokens)
            
            # è°ƒç”¨å‡½æ•°
            combined_query = self.sdvar_model._build_combined_query(draft_tokens, state, B)
            
            # éªŒè¯ç»“æœ
            expected_batch_size = 2 * B  # CFG doubling
            total_tokens = sum(state.patch_nums[i] ** 2 for i in range(len(draft_tokens)))
            
            checks = {
                "è¿”å›tensor": isinstance(combined_query, torch.Tensor),
                "batchç»´åº¦": combined_query.shape[0] == expected_batch_size,
                "tokenç»´åº¦": combined_query.shape[1] == total_tokens,
                "ç‰¹å¾ç»´åº¦": combined_query.shape[2] == 1024,  # embed_dim
                "æ— NaNå€¼": not torch.isnan(combined_query).any(),
                "æ— Infå€¼": not torch.isinf(combined_query).any(),
            }
            
            failed_checks = [k for k, v in checks.items() if not v]
            
            if failed_checks:
                return False, f"æ£€æŸ¥å¤±è´¥: {failed_checks}", checks
            else:
                return True, f"æ„å»ºæˆåŠŸ {combined_query.shape}", checks
                
        except Exception as e:
            return False, f"æ„å»ºå¼‚å¸¸: {str(e)}", {}
    
    def test_split_logits_by_stage(self, B: int = 2, gamma: int = 2) -> Tuple[bool, str, Dict[str, Any]]:
        """æµ‹è¯•logitsåˆ†å‰²"""
        try:
            if self.sdvar_model is None:
                return False, "SDVARæ¨¡å‹æœªåˆå§‹åŒ–", {}
                
            env_ok, _ = check_environment()
            if not env_ok:
                return False, "ç¯å¢ƒæ£€æŸ¥å¤±è´¥", {}
                
            import torch
            
            # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
            state = self.sdvar_model._initialize_inference_state(
                B=B, label_B=torch.tensor([980, 437]), g_seed=42, cfg=1.5, gamma=gamma
            )
            
            # æ¨¡æ‹Ÿdraft tokens
            draft_tokens = []
            total_tokens = 0
            for i in range(gamma):
                stage_idx = state.current_stage + i
                if stage_idx >= len(state.patch_nums):
                    break
                pn = state.patch_nums[stage_idx]
                tokens = torch.randint(0, 4096, (B, pn * pn), device=state.draft_f_hat.device)
                draft_tokens.append(tokens)
                total_tokens += pn * pn
            
            # æ¨¡æ‹Ÿtarget logits
            target_logits = torch.randn(2 * B, total_tokens, 4096, device=state.draft_f_hat.device)
            
            # è°ƒç”¨å‡½æ•°
            logits_per_stage = self.sdvar_model._split_logits_by_stage(
                target_logits, draft_tokens, B, state
            )
            
            # éªŒè¯ç»“æœ
            checks = {
                "è¿”å›åˆ—è¡¨": isinstance(logits_per_stage, list),
                "é•¿åº¦åŒ¹é…": len(logits_per_stage) == len(draft_tokens),
                "å½¢çŠ¶æ­£ç¡®": True,  # ç¨åè¯¦ç»†æ£€æŸ¥
            }
            
            # æ£€æŸ¥æ¯ä¸ªstageçš„logitså½¢çŠ¶
            for i, (stage_logits, draft_stage) in enumerate(zip(logits_per_stage, draft_tokens)):
                expected_tokens = draft_stage.shape[1]  # pn * pn
                if stage_logits.shape != (2 * B, expected_tokens, 4096):
                    checks["å½¢çŠ¶æ­£ç¡®"] = False
                    break
            
            failed_checks = [k for k, v in checks.items() if not v]
            
            if failed_checks:
                return False, f"æ£€æŸ¥å¤±è´¥: {failed_checks}", checks
            else:
                return True, f"åˆ†å‰²æˆåŠŸ {len(logits_per_stage)} stages", checks
                
        except Exception as e:
            return False, f"åˆ†å‰²å¼‚å¸¸: {str(e)}", {}
    
    def test_basic_token_matching(self, B: int = 2, gamma: int = 2) -> Tuple[bool, str, Dict[str, Any]]:
        """æµ‹è¯•åŸºç¡€tokenåŒ¹é…"""
        try:
            if self.sdvar_model is None:
                return False, "SDVARæ¨¡å‹æœªåˆå§‹åŒ–", {}
                
            env_ok, _ = check_environment()
            if not env_ok:
                return False, "ç¯å¢ƒæ£€æŸ¥å¤±è´¥", {}
                
            import torch
            
            # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
            state = self.sdvar_model._initialize_inference_state(
                B=B, label_B=torch.tensor([980, 437]), g_seed=42, cfg=1.5, gamma=gamma
            )
            
            # æ¨¡æ‹Ÿperfect matchingåœºæ™¯
            draft_tokens = []
            target_logits = []
            
            for i in range(gamma):
                stage_idx = state.current_stage + i
                if stage_idx >= len(state.patch_nums):
                    break
                pn = state.patch_nums[stage_idx]
                
                # åˆ›å»ºdraft tokens
                tokens = torch.randint(0, 4096, (B, pn * pn), device=state.draft_f_hat.device)
                draft_tokens.append(tokens)
                
                # åˆ›å»ºå®Œç¾åŒ¹é…çš„target logits
                stage_logits = torch.randn(B, pn * pn, 4096, device=state.draft_f_hat.device)
                # ç¡®ä¿argmaxåŒ¹é…draft tokens
                stage_logits.scatter_(dim=2, index=tokens.unsqueeze(2), value=100.0)
                target_logits.append(stage_logits)
            
            # è°ƒç”¨å‡½æ•°
            accept_length = self.sdvar_model.basic_token_matching(
                draft_tokens, target_logits, state, B, similarity_threshold=0.5, verbose=False
            )
            
            # éªŒè¯ç»“æœ
            checks = {
                "è¿”å›æ•´æ•°": isinstance(accept_length, int),
                "èŒƒå›´æ­£ç¡®": 0 <= accept_length <= len(draft_tokens),
                "å®Œç¾åŒ¹é…": accept_length == len(draft_tokens),  # æˆ‘ä»¬è®¾è®¡çš„æ˜¯å®Œç¾åŒ¹é…
            }
            
            failed_checks = [k for k, v in checks.items() if not v]
            
            if failed_checks:
                return False, f"æ£€æŸ¥å¤±è´¥: {failed_checks}", checks
            else:
                return True, f"åŒ¹é…æˆåŠŸ {accept_length}/{len(draft_tokens)} stages", checks
                
        except Exception as e:
            return False, f"åŒ¹é…å¼‚å¸¸: {str(e)}", {}
    
    def run_all_tests(self, B: int = 2, gamma: int = 2):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹SDVAR parallel_v1 æµ‹è¯•")
        print(f"ğŸ“Š æµ‹è¯•å‚æ•°: B={B}, gamma={gamma}")
        print("="*60)
        
        # æŒ‰é¡ºåºè¿è¡Œæ‰€æœ‰æµ‹è¯•
        tests = [
            (self.test_environment_check, "ç¯å¢ƒæ£€æŸ¥"),
            (self.test_state_initialization, "çŠ¶æ€åˆå§‹åŒ–æµ‹è¯•"),
            (self.test_draft_generate_batch, "Draftæ‰¹é‡ç”Ÿæˆæµ‹è¯•"),
            (self.test_build_combined_query, "Combined Queryæ„å»ºæµ‹è¯•"),
            (self.test_split_logits_by_stage, "Logitsåˆ†å‰²æµ‹è¯•"),
            (self.test_basic_token_matching, "åŸºç¡€TokenåŒ¹é…æµ‹è¯•"),
        ]
        
        for test_func, test_name in tests:
            if test_name == "ç¯å¢ƒæ£€æŸ¥":
                self.test_framework.run_test(test_func, test_name)
            else:
                self.test_framework.run_test(test_func, test_name, B, gamma)
            
        # æ‰“å°æ‘˜è¦
        self.test_framework.print_summary()
        
        return self.test_framework.test_results


def create_usage_example():
    """åˆ›å»ºä½¿ç”¨ç¤ºä¾‹"""
    print("ğŸ”§ SDVAR Parallel v1.0 æµ‹è¯•æ¡†æ¶ä½¿ç”¨æŒ‡å—")
    print("="*60)
    print()
    print("1. åœ¨Google Colabä¸­ä½¿ç”¨:")
    print("```python")
    print("# å¯¼å…¥æµ‹è¯•æ¡†æ¶")
    print("from sdvar_test_framework import SDVARParallelV1Tester")
    print("from models.var import SDVAR")
    print()
    print("# æ„å»ºä½ çš„SDVARæ¨¡å‹")
    print("sdvar_model = SDVAR(draft_model, target_model)")
    print()
    print("# è¿è¡Œæµ‹è¯•")
    print("tester = SDVARParallelV1Tester(sdvar_model)")
    print("results = tester.run_all_tests(B=2, gamma=2)")
    print()
    print("# æ£€æŸ¥ç»“æœ")
    print("passed_tests = [r for r in results if r.passed]")
    print("failed_tests = [r for r in results if not r.passed]")
    print("print(f'é€šè¿‡: {len(passed_tests)}, å¤±è´¥: {len(failed_tests)}')")
    print("```")
    print()
    print("2. å•ç‹¬æµ‹è¯•æŸä¸ªå‡½æ•°:")
    print("```python")
    print("# åªæµ‹è¯•çŠ¶æ€åˆå§‹åŒ–")
    print("result = tester.test_state_initialization(B=1, gamma=1)")
    print("print(result)")
    print()
    print("# åªæµ‹è¯•combined queryæ„å»º")
    print("result = tester.test_build_combined_query(B=2, gamma=2)")
    print("print(result)")
    print("```")
    print()
    print("3. è°ƒè¯•å¤±è´¥çš„æµ‹è¯•:")
    print("```python")
    print("for result in results:")
    print("    if not result.passed:")
    print("        print(f'å¤±è´¥æµ‹è¯•: {result.test_name}')")
    print("        print(f'é”™è¯¯ä¿¡æ¯: {result.message}')")
    print("        if result.details:")
    print("            print('è¯¦ç»†ä¿¡æ¯:', result.details)")
    print("```")


if __name__ == "__main__":
    create_usage_example() 