{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzCcY0hobdw5"
      },
      "source": [
        "## 初始下载"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzUQLl8nB2FK",
        "outputId": "760eba12-36ef-4f4a-92fe-c4870d06f83b"
      },
      "outputs": [],
      "source": [
        "%cd /content/\n",
        "!rm -rf /content/*\n",
        "!rm -rf /content/SDVAR\n",
        "!git clone --depth=1 https://github.com/lijrjyan/SDVAR.git\n",
        "%cd SDVAR\n",
        "!git log -1\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRuhS0uJ4Yu2",
        "outputId": "7ea94ffd-c774-4cbf-adf8-aeffd9fdf853"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX8ff7vW3WWG"
      },
      "source": [
        "# SDVAR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3G7Lb9M0gXl1"
      },
      "outputs": [],
      "source": [
        "################## 1. Download checkpoints and build models\n",
        "import os\n",
        "import os.path as osp\n",
        "import torch, torchvision\n",
        "import random\n",
        "import numpy as np\n",
        "import PIL.Image as PImage, PIL.ImageDraw as PImageDraw\n",
        "# 1. 添加根目录\n",
        "import sys\n",
        "sys.path.append('/content/SDVAR')\n",
        "\n",
        "# 2. 强制刷新模块\n",
        "import importlib\n",
        "import models\n",
        "importlib.reload(models)\n",
        "setattr(torch.nn.Linear, 'reset_parameters', lambda self: None)     # disable default parameter init for faster speed\n",
        "setattr(torch.nn.LayerNorm, 'reset_parameters', lambda self: None)  # disable default parameter init for faster speed\n",
        "from models import VQVAE, build_vae_var_speculative_decoding, build_vae_var\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6I5qhWM4gcaD"
      },
      "outputs": [],
      "source": [
        "DRAFT_MODEL_DEPTH = 16    # TODO: =====> please specify MODEL_DEPTH <=====\n",
        "assert DRAFT_MODEL_DEPTH in {16, 20, 24, 30}\n",
        "TARGET_MODEL_DEPTH = 30    # TODO: =====> please specify MODEL_DEPTH <=====\n",
        "assert TARGET_MODEL_DEPTH in {16, 20, 24, 30}\n",
        "\n",
        "# download checkpoint\n",
        "hf_home = 'https://huggingface.co/FoundationVision/var/resolve/main'\n",
        "vae_ckpt, target_var_ckpt, draft_var_ckpt = 'vae_ch160v4096z32.pth', f'var_d{TARGET_MODEL_DEPTH}.pth', f'var_d{DRAFT_MODEL_DEPTH}.pth'\n",
        "if not osp.exists(vae_ckpt): os.system(f'wget {hf_home}/{vae_ckpt}')\n",
        "if not osp.exists(target_var_ckpt): os.system(f'wget {hf_home}/{target_var_ckpt}')\n",
        "if not osp.exists(draft_var_ckpt): os.system(f'wget {hf_home}/{draft_var_ckpt}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtR3pgphge6f"
      },
      "outputs": [],
      "source": [
        "# set args\n",
        "seed = 0 #@param {type:\"numbe\n",
        "\n",
        "num_sampling_steps = 200 #@param {type:\"slider\", min:0, max:1000, step:1}\n",
        "cfg = 3 #@param {type:\"slider\", min:1, max:10, step:0.1}\n",
        "class_labels = (980, 980, 437, 437, 22, 22, 562, 562)  #@param {type:\"raw\"}\n",
        "more_smooth = False # True for more smooth output\n",
        "entry_num = 0 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "sd_mask = 0 #@param {type:\"slider\", min:0, max:5, step:1}\n",
        "\n",
        "# seed\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# run faster\n",
        "tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = bool(tf32)\n",
        "torch.backends.cuda.matmul.allow_tf32 = bool(tf32)\n",
        "torch.set_float32_matmul_precision('high' if tf32 else 'highest')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrlkzWhaggi2"
      },
      "outputs": [],
      "source": [
        "# build vae, var\n",
        "patch_nums = (1, 2, 3, 4, 5, 6, 8, 10, 13, 16)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# sd_var =. sd需要写一个初始化函数，初始化函数内容包括draft和target model即可\n",
        "\n",
        "if 'vae' not in globals() or 'draft_var' not in globals() or 'target_var' not in globals():\n",
        "    vae, draft_var, target_var, sd_var = build_vae_var_speculative_decoding(\n",
        "        V=4096, Cvae=32, ch=160, share_quant_resi=4,    # hard-coded VQVAE hyperparameters\n",
        "        device=device, patch_nums=patch_nums,\n",
        "        num_classes=1000, depth_draft=DRAFT_MODEL_DEPTH, depth_target=TARGET_MODEL_DEPTH, shared_aln=False,\n",
        "    )\n",
        "\n",
        "# load checkpoints\n",
        "vae.load_state_dict(torch.load(vae_ckpt, map_location='cpu'), strict=True)\n",
        "# draft_var.load_state_dict(torch.load(draft_var_ckpt, map_location='cpu'), strict=True)\n",
        "# target_var.load_state_dict(torch.load(target_var_ckpt, map_location='cpu'), strict=True)\n",
        "target_var.load_state_dict(torch.load(target_var_ckpt, map_location='cpu'), strict=True)\n",
        "draft_var.load_state_dict(torch.load(draft_var_ckpt, map_location='cpu'), strict=True)\n",
        "vae.eval(), draft_var.eval(), target_var.eval()\n",
        "for p in vae.parameters(): p.requires_grad_(False)\n",
        "for p in draft_var.parameters(): p.requires_grad_(False)\n",
        "for p in target_var.parameters(): p.requires_grad_(False)\n",
        "print(f'prepare finished.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yIWOcVxzgi84",
        "outputId": "6bfd96a0-f88d-485f-aa7f-57f92ff23f7e"
      },
      "outputs": [],
      "source": [
        "############################# 3. Speculative decoding\n",
        "import time\n",
        "\n",
        "for entry_num in range(0, 11):\n",
        "    print(f\"Generating for entry_num = {entry_num}\")\n",
        "    start_time = time.time() # Record the start time\n",
        "    B = len(class_labels)\n",
        "    label_B: torch.LongTensor = torch.tensor(class_labels, device=device)\n",
        "    recon_B3HW = sd_var.sdvar_autoregressive_infer_cfg_sd_test3(\n",
        "        B=B,\n",
        "        label_B=label_B,\n",
        "        cfg=cfg,\n",
        "        top_k=900,\n",
        "        top_p=0.95,\n",
        "        g_seed=seed,\n",
        "        more_smooth=more_smooth,\n",
        "        entry_num=entry_num,\n",
        "        sd_mask=5\n",
        "    )\n",
        "    end_time = time.time() # Record the end time\n",
        "    time_taken = end_time - start_time # Calculate the duration\n",
        "    print(f\"Time taken for entry_num {entry_num}: {time_taken:.2f} seconds\") # Print the time taken\n",
        "\n",
        "    chw = torchvision.utils.make_grid(recon_B3HW, nrow=8, padding=0, pad_value=1.0)\n",
        "    chw = chw.permute(1, 2, 0).mul_(255).cpu().numpy()\n",
        "    chw = PImage.fromarray(chw.astype(np.uint8))\n",
        "    display(chw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRnbbUTD3jI8"
      },
      "source": [
        "## 常规"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKQ0mJMAM6Yu"
      },
      "outputs": [],
      "source": [
        "############################# 3. Speculative decoding\n",
        "\n",
        "\n",
        "for entry_num in range(0, 11):\n",
        "    print(f\"Generating for entry_num = {entry_num}\")\n",
        "\n",
        "    B = len(class_labels)\n",
        "    label_B: torch.LongTensor = torch.tensor(class_labels, device=device)\n",
        "    recon_B3HW = sd_var.sdvar_autoregressive_infer_cfg_sd_test3_with_debug_log(\n",
        "        B=B,\n",
        "        label_B=label_B,\n",
        "        cfg=0,\n",
        "        top_k=900,\n",
        "        top_p=0.95,\n",
        "        g_seed=seed,\n",
        "        more_smooth=more_smooth,\n",
        "        entry_num=entry_num,\n",
        "        sd_mask=5\n",
        "    )\n",
        "\n",
        "    chw = torchvision.utils.make_grid(recon_B3HW, nrow=8, padding=0, pad_value=1.0)\n",
        "    chw = chw.permute(1, 2, 0).mul_(255).cpu().numpy()\n",
        "    chw = PImage.fromarray(chw.astype(np.uint8))\n",
        "    # display(chw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X84U6HY0PpX4"
      },
      "source": [
        "下载模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GPupWVUJpC6"
      },
      "outputs": [],
      "source": [
        "  ################## 1. Download checkpoints and build models\n",
        "import os\n",
        "import os.path as osp\n",
        "import torch, torchvision\n",
        "import random\n",
        "import numpy as np\n",
        "import PIL.Image as PImage, PIL.ImageDraw as PImageDraw\n",
        "from IPython.display import display\n",
        "setattr(torch.nn.Linear, 'reset_parameters', lambda self: None)     # disable default parameter init for faster speed\n",
        "setattr(torch.nn.LayerNorm, 'reset_parameters', lambda self: None)  # disable default parameter init for faster speed\n",
        "from models import VQVAE, build_vae_var_speculative_decoding, build_vae_var\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCJH5tsdP241"
      },
      "outputs": [],
      "source": [
        "MODEL_DEPTH = 16    # TODO: =====> please specify MODEL_DEPTH <=====\n",
        "assert MODEL_DEPTH in {16, 20, 24, 30}\n",
        "\n",
        "\n",
        "# download checkpoint\n",
        "hf_home = 'https://huggingface.co/FoundationVision/var/resolve/main'\n",
        "vae_ckpt, var_ckpt = 'vae_ch160v4096z32.pth', f'var_d{MODEL_DEPTH}.pth'\n",
        "if not osp.exists(vae_ckpt): os.system(f'wget {hf_home}/{vae_ckpt}')\n",
        "if not osp.exists(var_ckpt): os.system(f'wget {hf_home}/{var_ckpt}')\n",
        "\n",
        "# build vae, var\n",
        "patch_nums = (1, 2, 3, 4, 5, 6, 8, 10, 13, 16)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "if 'vae' not in globals() or 'var' not in globals():\n",
        "    vae, var = build_vae_var(\n",
        "        V=4096, Cvae=32, ch=160, share_quant_resi=4,    # hard-coded VQVAE hyperparameters\n",
        "        device=device, patch_nums=patch_nums,\n",
        "        num_classes=1000, depth=MODEL_DEPTH, shared_aln=False,\n",
        "    )\n",
        "\n",
        "# load checkpoints\n",
        "vae.load_state_dict(torch.load(vae_ckpt, map_location='cpu'), strict=True)\n",
        "var.load_state_dict(torch.load(var_ckpt, map_location='cpu'), strict=True)\n",
        "vae.eval(), var.eval()\n",
        "for p in vae.parameters(): p.requires_grad_(False)\n",
        "for p in var.parameters(): p.requires_grad_(False)\n",
        "print(f'prepare finished.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "TQPOXrOkF-LH",
        "outputId": "cf5f4ca7-9575-4821-f0c8-efe53a0b941d"
      },
      "outputs": [],
      "source": [
        "############################# 2. Sample with classifier-free guidance\n",
        "\n",
        "# set args\n",
        "seed = 0 #@param {type:\"number\"}\n",
        "torch.manual_seed(seed)\n",
        "num_sampling_steps = 250 #@param {type:\"slider\", min:0, max:1000, step:1}\n",
        "cfg = 4 #@param {type:\"slider\", min:1, max:10, step:0.1}\n",
        "class_labels = (980, 980, 437, 437, 22, 22, 562, 562)  #@param {type:\"raw\"}\n",
        "more_smooth = False # True for more smooth output\n",
        "\n",
        "# seed\n",
        "torch.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# run faster\n",
        "tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = bool(tf32)\n",
        "torch.backends.cuda.matmul.allow_tf32 = bool(tf32)\n",
        "torch.set_float32_matmul_precision('high' if tf32 else 'highest')\n",
        "\n",
        "# sample\n",
        "B = len(class_labels)\n",
        "label_B: torch.LongTensor = torch.tensor(class_labels, device=device)\n",
        "# with torch.inference_mode():\n",
        "#     with torch.autocast('cuda', enabled=True, dtype=torch.float16, cache_enabled=True):    # using bfloat16 can be faster\n",
        "recon_B3HW = var.autoregressive_infer_cfg(B=B, label_B=label_B, cfg=cfg, top_k=900, top_p=0.95, g_seed=seed, more_smooth=more_smooth)\n",
        "\n",
        "chw = torchvision.utils.make_grid(recon_B3HW, nrow=8, padding=0, pad_value=1.0)\n",
        "chw = chw.permute(1, 2, 0).mul_(255).cpu().numpy()\n",
        "chw = PImage.fromarray(chw.astype(np.uint8))\n",
        "display(chw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "kunpY4DKA-Dl",
        "outputId": "471dd58f-5f5c-4be4-fffb-f19c6bf2970c"
      },
      "outputs": [],
      "source": [
        "############################# 2. Sample with classifier-free guidance\n",
        "\n",
        "# set args\n",
        "seed = 0 #@param {type:\"number\"}\n",
        "torch.manual_seed(seed)\n",
        "num_sampling_steps = 250 #@param {type:\"slider\", min:0, max:1000, step:1}\n",
        "cfg = 4 #@param {type:\"slider\", min:1, max:10, step:0.1}\n",
        "class_labels = (980, 980, 437, 437, 22, 22, 562, 562)  #@param {type:\"raw\"}\n",
        "more_smooth = False # True for more smooth output\n",
        "\n",
        "# seed\n",
        "torch.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# run faster\n",
        "tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = bool(tf32)\n",
        "torch.backends.cuda.matmul.allow_tf32 = bool(tf32)\n",
        "torch.set_float32_matmul_precision('high' if tf32 else 'highest')\n",
        "\n",
        "# sample\n",
        "B = len(class_labels)\n",
        "label_B: torch.LongTensor = torch.tensor(class_labels, device=device)\n",
        "# with torch.inference_mode():\n",
        "#     with torch.autocast('cuda', enabled=True, dtype=torch.float16, cache_enabled=True):    # using bfloat16 can be faster\n",
        "recon_B3HW = var.autoregressive_infer_cfg1(B=B, label_B=label_B, cfg=cfg, top_k=900, top_p=0.95, g_seed=seed, more_smooth=more_smooth)\n",
        "\n",
        "chw = torchvision.utils.make_grid(recon_B3HW, nrow=8, padding=0, pad_value=1.0)\n",
        "chw = chw.permute(1, 2, 0).mul_(255).cpu().numpy()\n",
        "chw = PImage.fromarray(chw.astype(np.uint8))\n",
        "display(chw)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
