# SDVAR Parallel v1.0 ä¿®å¤æ­¥éª¤æŒ‡å—

## ğŸ¯ ç›®æ ‡
ä¿®å¤`sdvar_autoregressive_infer_cfg_parallel_v1`å‡½æ•°ï¼Œç¡®ä¿å®ƒèƒ½å¤Ÿæ­£ç¡®è¿è¡Œå¹¶å®ç°é¢„æœŸçš„å¹¶è¡ŒéªŒè¯åŠŸèƒ½ã€‚

---

## ğŸ“‹ ä¿®å¤ä¼˜å…ˆçº§

### ğŸ”´ ä¼˜å…ˆçº§1: å…³é”®bugä¿®å¤ (ç«‹å³ä¿®å¤)
1. **`_build_combined_query`å‡½æ•°** - ä½ç½®ç¼–ç å’ŒCFGå¤„ç†é”™è¯¯
2. **`_split_logits_by_stage`å‡½æ•°** - CFGç»´åº¦åˆ†å‰²é”™è¯¯  
3. **çŠ¶æ€æ›´æ–°é€»è¾‘** - é¿å…f_hatåŒé‡æ›´æ–°

### ğŸŸ¡ ä¼˜å…ˆçº§2: é‡è¦æ”¹è¿› (åç»­ä¿®å¤)
1. **`_get_attention_mask`å‡½æ•°** - å®ç°åŸºç¡€å—çº§æ©ç 
2. **é”™è¯¯å¤„ç†æ”¹è¿›** - æ·»åŠ è¾¹ç•Œæ£€æŸ¥
3. **KV Cacheä¼˜åŒ–** - æ˜ç¡®ç¼“å­˜ç®¡ç†

---

## ğŸ› ï¸ ç¬¬ä¸€æ­¥ï¼šä¿®å¤`_build_combined_query`å‡½æ•°

### å½“å‰é—®é¢˜
```python
# å½“å‰ä»£ç çš„é—®é¢˜ä½ç½®
current_pos = sum(p**2 for p in state.patch_nums[:state.current_stage])
```

### ä¿®å¤æ–¹æ¡ˆ
åœ¨`models/var.py`ä¸­æ‰¾åˆ°`_build_combined_query`å‡½æ•°ï¼ˆçº¦ç¬¬1224è¡Œï¼‰ï¼Œæ›¿æ¢ä¸ºï¼š

```python
def _build_combined_query(self, draft_tokens: List[torch.Tensor], 
                         state, B: int) -> torch.Tensor:
    """ä¿®å¤ç‰ˆæœ¬çš„combined queryæ„å»º"""
    if not draft_tokens:
        return torch.empty(2 * B, 0, 1024, device=state.draft_f_hat.device)
    
    if verbose := True:  # è°ƒè¯•å¼€å…³
        print(f"[SDVAR] Building combined query for {len(draft_tokens)} stages")
    
    # 1. æ­£ç¡®è®¡ç®—ä½ç½®åç§»
    base_pos = sum(p**2 for p in state.patch_nums[:state.current_stage])
    if verbose:
        print(f"[SDVAR] Base position: {base_pos}, current_stage: {state.current_stage}")
    
    # 2. æ„å»ºå®Œæ•´è¾“å…¥åºåˆ—
    all_embeddings = []
    
    # 3. å¦‚æœæ˜¯ç¬¬ä¸€é˜¶æ®µï¼Œéœ€è¦æ·»åŠ first_token_map
    if state.current_stage == 0:
        # è·å–ç¬¬ä¸€å±‚çš„token map
        first_l = self.target_model.first_l
        sos = state.target_cond_BD[:B]  # åªå–å‰Bä¸ªï¼Œä¸è¦CFG doubling
        
        first_token_map = (
            sos.unsqueeze(1).expand(B, first_l, -1) +
            self.target_model.pos_start.expand(B, first_l, -1) +
            state.target_lvl_pos[:1, :first_l].expand(B, -1, -1)
        )
        all_embeddings.append(first_token_map)
        current_pos = first_l
        
        if verbose:
            print(f"[SDVAR] Added first_token_map: {first_token_map.shape}")
    else:
        current_pos = base_pos
        # TODO: æ·»åŠ ä¹‹å‰å·²æ¥å—çš„tokens (Week 2åŠŸèƒ½)
        if verbose:
            print(f"[SDVAR] Skipping first layer, starting from position: {current_pos}")
    
    # 4. å¤„ç†æ¯ä¸ªdraft token stage
    for stage_idx, tokens in enumerate(draft_tokens):
        current_stage = state.current_stage + stage_idx
        pn = state.patch_nums[current_stage]
        
        if verbose:
            print(f"[SDVAR] Processing stage {current_stage}, tokens: {tokens.shape}, pn: {pn}")
        
        # æ­£ç¡®çš„embeddingè·¯å¾„ï¼štokens -> VAE embedding -> word embedding
        vae_embedding = self.target_model.vae_quant_proxy[0].embedding(tokens)  # (B, pn*pn, Cvae)
        stage_embedding = self.target_model.word_embed(vae_embedding)  # (B, pn*pn, C)
        
        # æ·»åŠ ä½ç½®ç¼–ç 
        pos_embed = state.target_lvl_pos[:1, current_pos:current_pos + pn*pn].expand(B, -1, -1)
        stage_embedding = stage_embedding + pos_embed
        
        all_embeddings.append(stage_embedding)
        current_pos += pn * pn
        
        if verbose:
            print(f"[SDVAR] Stage {current_stage} embedding: {stage_embedding.shape}")
    
    # 5. æ‹¼æ¥æ‰€æœ‰embeddingså¹¶è¿›è¡ŒCFG doubling
    combined = torch.cat(all_embeddings, dim=1)  # B, total_tokens, C
    combined = combined.repeat(2, 1, 1)  # CFG doubling -> 2B, total_tokens, C
    
    if verbose:
        print(f"[SDVAR] Final combined query: {combined.shape}")
    
    return combined
```

### æµ‹è¯•ç¬¬ä¸€æ­¥ä¿®å¤
åœ¨ä¿®å¤åï¼Œè¿è¡Œæµ‹è¯•ï¼š

```python
# åœ¨Colabä¸­æµ‹è¯•
from sdvar_test_framework import SDVARParallelV1Tester
tester = SDVARParallelV1Tester(sdvar_model)

# åªæµ‹è¯•è¿™ä¸ªå‡½æ•°
result = tester.test_build_combined_query(B=2, gamma=2)
print("ä¿®å¤ç»“æœ:", result)
```

---

## ğŸ› ï¸ ç¬¬äºŒæ­¥ï¼šä¿®å¤`_split_logits_by_stage`å‡½æ•°

### ä¿®å¤æ–¹æ¡ˆ
æ‰¾åˆ°`_split_logits_by_stage`å‡½æ•°ï¼ˆçº¦ç¬¬1288è¡Œï¼‰ï¼Œæ›¿æ¢ä¸ºï¼š

```python
def _split_logits_by_stage(self, target_logits: torch.Tensor, 
                          draft_tokens: List[torch.Tensor], B: int, state) -> List[torch.Tensor]:
    """ä¿®å¤ç‰ˆæœ¬çš„logitsåˆ†å‰²"""
    if not draft_tokens:
        return []
    
    verbose = True  # è°ƒè¯•å¼€å…³
    if verbose:
        print(f"[SDVAR] Splitting logits: {target_logits.shape}")
    
    # 1. éªŒè¯CFGç»´åº¦
    expected_batch = 2 * B
    if target_logits.shape[0] != expected_batch:
        raise ValueError(f"Expected batch size {expected_batch}, got {target_logits.shape[0]}")
    
    # 2. è®¡ç®—æ­£ç¡®çš„èµ·å§‹ä½ç½®
    base_pos = 0
    if state.current_stage == 0:
        base_pos = self.target_model.first_l  # è·³è¿‡ç¬¬ä¸€å±‚
    else:
        base_pos = sum(p**2 for p in state.patch_nums[:state.current_stage])
    
    if verbose:
        print(f"[SDVAR] Base position: {base_pos}")
    
    # 3. åˆ†å‰²æ¯ä¸ªstageçš„logits
    logits_per_stage = []
    current_pos = base_pos
    
    for stage_idx, tokens in enumerate(draft_tokens):
        current_stage = state.current_stage + stage_idx
        pn = state.patch_nums[current_stage]
        stage_length = pn * pn
        
        # æ£€æŸ¥è¾¹ç•Œ
        if current_pos + stage_length > target_logits.shape[1]:
            if verbose:
                print(f"[SDVAR] Warning: Stage {current_stage} exceeds logits length")
            break
        
        # æå–è¿™ä¸ªstageçš„logits
        stage_logits = target_logits[:, current_pos:current_pos + stage_length, :]
        logits_per_stage.append(stage_logits)
        
        if verbose:
            print(f"[SDVAR] Stage {current_stage} logits: {stage_logits.shape}")
        
        current_pos += stage_length
    
    return logits_per_stage
```

### æµ‹è¯•ç¬¬äºŒæ­¥ä¿®å¤
```python
# æµ‹è¯•logitsåˆ†å‰²
result = tester.test_split_logits_by_stage(B=2, gamma=2)
print("åˆ†å‰²ä¿®å¤ç»“æœ:", result)
```

---

## ğŸ› ï¸ ç¬¬ä¸‰æ­¥ï¼šä¿®å¤çŠ¶æ€æ›´æ–°é€»è¾‘

### é—®é¢˜åˆ†æ
å½“å‰`update_state_with_accepted_tokens`å‡½æ•°å’Œä¸»å¾ªç¯éƒ½åœ¨æ›´æ–°f_hatï¼Œå¯¼è‡´ä¸ä¸€è‡´ã€‚

### ä¿®å¤æ–¹æ¡ˆ
ä¿®æ”¹ä¸»å‡½æ•°`sdvar_autoregressive_infer_cfg_parallel_v1`ä¸­çš„çŠ¶æ€æ›´æ–°éƒ¨åˆ†ï¼š

```python
# åœ¨ä¸»å‡½æ•°ä¸­æ‰¾åˆ°è¿™ä¸ªéƒ¨åˆ†ï¼ˆçº¦ç¬¬1520è¡Œé™„è¿‘ï¼‰
# 4. æ›´æ–°æ¨ç†çŠ¶æ€
if accept_length > 0:
    # æ³¨é‡Šæ‰è¿™è¡Œï¼Œé¿å…åŒé‡æ›´æ–°
    # self.update_state_with_accepted_tokens(draft_tokens, accept_length, state, B)
    
    # ç›´æ¥åœ¨è¿™é‡Œæ›´æ–°çŠ¶æ€
    for stage_idx in range(accept_length):
        current_stage = state.current_stage + stage_idx
        pn = state.patch_nums[current_stage]
        
        # è·å–è¿™ä¸€å±‚çš„tokens
        stage_tokens = draft_tokens[stage_idx]
        
        # è½¬æ¢å¹¶æ›´æ–°f_hat
        h_BChw = self.draft_model.vae_quant_proxy[0].embedding(stage_tokens)
        h_BChw = h_BChw.transpose(1, 2).reshape(B, self.draft_model.Cvae, pn, pn)
        
        # åŒæ—¶æ›´æ–°draftå’Œtargetçš„f_hat
        state.draft_f_hat, _ = self.draft_model.vae_quant_proxy[0].get_next_autoregressive_input(
            current_stage, state.total_stages, state.draft_f_hat, h_BChw
        )
        state.target_f_hat = state.draft_f_hat.clone()  # ä¿æŒåŒæ­¥
    
    if verbose:
        print(f"[SDVAR] Successfully processed {accept_length} stages")
```

---

## ğŸ› ï¸ ç¬¬å››æ­¥ï¼šå®Œæ•´åŠŸèƒ½æµ‹è¯•

### è¿è¡Œå®Œæ•´æµ‹è¯•
```python
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
results = tester.run_all_tests(B=2, gamma=2)

# åˆ†æç»“æœ
passed_tests = [r for r in results if r.passed]
failed_tests = [r for r in results if not r.passed]

print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
print(f"âœ… é€šè¿‡: {len(passed_tests)}")
print(f"âŒ å¤±è´¥: {len(failed_tests)}")

if failed_tests:
    print(f"\nğŸ” å¤±è´¥çš„æµ‹è¯•:")
    for test in failed_tests:
        print(f"- {test.test_name}: {test.message}")
```

### ç«¯åˆ°ç«¯æµ‹è¯•
```python
# æµ‹è¯•å®é™…æ¨ç†
try:
    print("ğŸ§ª ç«¯åˆ°ç«¯æ¨ç†æµ‹è¯•")
    result_img = sdvar_model.sdvar_autoregressive_infer_cfg_parallel_v1(
        B=1,
        label_B=torch.tensor([980]),  # volcano class
        gamma=2,
        cfg=1.5,
        verbose=True
    )
    print(f"âœ… æ¨ç†æˆåŠŸ! è¾“å‡ºå½¢çŠ¶: {result_img.shape}")
    
    # ä¿å­˜ç»“æœå›¾åƒ
    from torchvision.utils import save_image
    save_image(result_img, 'sdvar_parallel_v1_test.png')
    print("ğŸ–¼ï¸ å›¾åƒå·²ä¿å­˜ä¸º sdvar_parallel_v1_test.png")
    
except Exception as e:
    print(f"âŒ ç«¯åˆ°ç«¯æµ‹è¯•å¤±è´¥: {str(e)}")
    import traceback
    traceback.print_exc()
```

---

## ğŸ”§ è°ƒè¯•æŠ€å·§

### 1. å¯ç”¨è¯¦ç»†æ—¥å¿—
```python
# åœ¨æµ‹è¯•æ—¶å¯ç”¨verboseæ¨¡å¼
result_img = sdvar_model.sdvar_autoregressive_infer_cfg_parallel_v1(
    B=1, label_B=torch.tensor([980]), gamma=2, verbose=True
)
```

### 2. å½¢çŠ¶æ£€æŸ¥
```python
# åœ¨å…³é”®ä½ç½®æ·»åŠ å½¢çŠ¶æ£€æŸ¥
def debug_shapes(tensor, name):
    print(f"ğŸ” {name}: {tensor.shape} | device: {tensor.device} | dtype: {tensor.dtype}")

# åœ¨å‡½æ•°ä¸­ä½¿ç”¨
debug_shapes(combined_query, "combined_query")
debug_shapes(target_logits, "target_logits")
```

### 3. æ¯”è¾ƒwith test3
```python
# å¯¹æ¯”æ–°æ—§å®ç°çš„ç»“æœ
old_result = sdvar_model.sdvar_autoregressive_infer_cfg_sd_test3(
    B=1, label_B=torch.tensor([980]), entry_num=5, sd_mask=0
)
new_result = sdvar_model.sdvar_autoregressive_infer_cfg_parallel_v1(
    B=1, label_B=torch.tensor([980]), gamma=2
)

# è®¡ç®—å·®å¼‚
diff = torch.abs(old_result - new_result).mean()
print(f"å¹³å‡åƒç´ å·®å¼‚: {diff.item():.6f}")
```

---

## âœ… æˆåŠŸæ ‡å‡†

ä¿®å¤å®Œæˆåï¼Œä½ åº”è¯¥èƒ½çœ‹åˆ°ï¼š

1. **æµ‹è¯•é€šè¿‡**: æ‰€æœ‰å•å…ƒæµ‹è¯•éƒ½é€šè¿‡
2. **æ¨ç†æˆåŠŸ**: èƒ½å¤Ÿç”Ÿæˆå®Œæ•´çš„å›¾åƒ
3. **æ€§èƒ½æå‡**: Targetè°ƒç”¨æ¬¡æ•°å‡å°‘åˆ°2-5æ¬¡
4. **è´¨é‡ä¿æŒ**: ä¸test3å‡½æ•°ç»“æœç›¸ä¼¼ï¼ˆå·®å¼‚<0.01ï¼‰

---

## ğŸš€ ä¸‹ä¸€æ­¥è®¡åˆ’

å®ŒæˆåŸºç¡€ä¿®å¤åï¼ŒWeek 2å¯ä»¥å®ç°ï¼š
- åŠ¨æ€Î³è°ƒæ•´ç­–ç•¥
- é«˜çº§tokenåŒ¹é…ç®—æ³•
- æ›´å¤æ‚çš„æ³¨æ„åŠ›æ©ç 
- æ€§èƒ½ä¼˜åŒ–å’Œå†…å­˜ç®¡ç†

---

**ğŸ’¡ æç¤º**: ä¸€æ¬¡åªä¿®å¤ä¸€ä¸ªå‡½æ•°ï¼Œæ¯æ¬¡ä¿®å¤åéƒ½è¦æµ‹è¯•ï¼Œç¡®ä¿æ²¡æœ‰å¼•å…¥æ–°çš„é—®é¢˜ï¼ 