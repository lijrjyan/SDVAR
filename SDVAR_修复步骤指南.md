# SDVAR Parallel v1.0 ä¿®å¤æ­¥éª¤æŒ‡å—

## ğŸ¯ ç›®æ ‡
ä¿®å¤`sdvar_autoregressive_infer_cfg_parallel_v1`å‡½æ•°ï¼Œç¡®ä¿å®ƒèƒ½å¤Ÿæ­£ç¡®è¿è¡Œå¹¶å®ç°é¢„æœŸçš„å¹¶è¡ŒéªŒè¯åŠŸèƒ½ã€‚

---

## ğŸ“‹ ä¿®å¤ä¼˜å…ˆçº§

### ğŸ”´ ä¼˜å…ˆçº§1: å…³é”®bugä¿®å¤ (ç«‹å³ä¿®å¤)
1. **`_build_combined_query`å‡½æ•°** - ä½ç½®ç¼–ç å’ŒCFGå¤„ç†é”™è¯¯
2. **`_split_logits_by_stage`å‡½æ•°** - CFGç»´åº¦åˆ†å‰²é”™è¯¯  
3. **çŠ¶æ€æ›´æ–°é€»è¾‘** - é¿å…f_hatåŒé‡æ›´æ–°

### ğŸŸ¡ ä¼˜å…ˆçº§2: é‡è¦æ”¹è¿› (åç»­ä¿®å¤)
1. **`_get_attention_mask`å‡½æ•°** - å®ç°åŸºç¡€å—çº§æ©ç 
2. **é”™è¯¯å¤„ç†æ”¹è¿›** - æ·»åŠ è¾¹ç•Œæ£€æŸ¥
3. **KV Cacheä¼˜åŒ–** - æ˜ç¡®ç¼“å­˜ç®¡ç†

---

## ğŸ› ï¸ ç¬¬ä¸€æ­¥ï¼šä¿®å¤`_build_combined_query`å‡½æ•°

### å½“å‰é—®é¢˜
```python
# å½“å‰ä»£ç çš„é—®é¢˜ä½ç½®
current_pos = sum(p**2 for p in state.patch_nums[:state.current_stage])
```

### ä¿®å¤æ–¹æ¡ˆ
åœ¨`models/var.py`ä¸­æ‰¾åˆ°`_build_combined_query`å‡½æ•°ï¼ˆçº¦ç¬¬1224è¡Œï¼‰ï¼Œæ›¿æ¢ä¸ºï¼š

```python
def _build_combined_query(self, draft_tokens: List[torch.Tensor], 
                         state, B: int) -> torch.Tensor:
    """ä¿®å¤ç‰ˆæœ¬çš„combined queryæ„å»º"""
    if not draft_tokens:
        return torch.empty(2 * B, 0, 1024, device=state.draft_f_hat.device)
    
    if verbose := True:  # è°ƒè¯•å¼€å…³
        print(f"[SDVAR] Building combined query for {len(draft_tokens)} stages")
    
    # 1. æ­£ç¡®è®¡ç®—ä½ç½®åç§»
    base_pos = sum(p**2 for p in state.patch_nums[:state.current_stage])
    if verbose:
        print(f"[SDVAR] Base position: {base_pos}, current_stage: {state.current_stage}")
    
    # 2. æ„å»ºå®Œæ•´è¾“å…¥åºåˆ—
    all_embeddings = []
    
    # 3. å¦‚æœæ˜¯ç¬¬ä¸€é˜¶æ®µï¼Œéœ€è¦æ·»åŠ first_token_map
    if state.current_stage == 0:
        # è·å–ç¬¬ä¸€å±‚çš„token map
        first_l = self.target_model.first_l
        sos = state.target_cond_BD[:B]  # åªå–å‰Bä¸ªï¼Œä¸è¦CFG doubling
        
        first_token_map = (
            sos.unsqueeze(1).expand(B, first_l, -1) +
            self.target_model.pos_start.expand(B, first_l, -1) +
            state.target_lvl_pos[:1, :first_l].expand(B, -1, -1)
        )
        all_embeddings.append(first_token_map)
        current_pos = first_l
        
        if verbose:
            print(f"[SDVAR] Added first_token_map: {first_token_map.shape}")
    else:
        current_pos = base_pos
        # TODO: æ·»åŠ ä¹‹å‰å·²æ¥å—çš„tokens (Week 2åŠŸèƒ½)
        if verbose:
            print(f"[SDVAR] Skipping first layer, starting from position: {current_pos}")
    
    # 4. å¤„ç†æ¯ä¸ªdraft token stage
    for stage_idx, tokens in enumerate(draft_tokens):
        current_stage = state.current_stage + stage_idx
        pn = state.patch_nums[current_stage]
        
        if verbose:
            print(f"[SDVAR] Processing stage {current_stage}, tokens: {tokens.shape}, pn: {pn}")
        
        # æ­£ç¡®çš„embeddingè·¯å¾„ï¼štokens -> VAE embedding -> word embedding
        vae_embedding = self.target_model.vae_quant_proxy[0].embedding(tokens)  # (B, pn*pn, Cvae)
        stage_embedding = self.target_model.word_embed(vae_embedding)  # (B, pn*pn, C)
        
        # æ·»åŠ ä½ç½®ç¼–ç 
        pos_embed = state.target_lvl_pos[:1, current_pos:current_pos + pn*pn].expand(B, -1, -1)
        stage_embedding = stage_embedding + pos_embed
        
        all_embeddings.append(stage_embedding)
        current_pos += pn * pn
        
        if verbose:
            print(f"[SDVAR] Stage {current_stage} embedding: {stage_embedding.shape}")
    
    # 5. æ‹¼æ¥æ‰€æœ‰embeddingså¹¶è¿›è¡ŒCFG doubling
    combined = torch.cat(all_embeddings, dim=1)  # B, total_tokens, C
    combined = combined.repeat(2, 1, 1)  # CFG doubling -> 2B, total_tokens, C
    
    if verbose:
        print(f"[SDVAR] Final combined query: {combined.shape}")
    
    return combined
```

### æµ‹è¯•ç¬¬ä¸€æ­¥ä¿®å¤
åœ¨ä¿®å¤åï¼Œè¿è¡Œæµ‹è¯•ï¼š

```python
# åœ¨Colabä¸­æµ‹è¯•
from sdvar_test_framework import SDVARParallelV1Tester
tester = SDVARParallelV1Tester(sdvar_model)

# åªæµ‹è¯•è¿™ä¸ªå‡½æ•°
result = tester.test_build_combined_query(B=2, gamma=2)
print("ä¿®å¤ç»“æœ:", result)
```

---

## ğŸ› ï¸ ç¬¬äºŒæ­¥ï¼šä¿®å¤`_split_logits_by_stage`å‡½æ•°

### ä¿®å¤æ–¹æ¡ˆ
æ‰¾åˆ°`_split_logits_by_stage`å‡½æ•°ï¼ˆçº¦ç¬¬1288è¡Œï¼‰ï¼Œæ›¿æ¢ä¸ºï¼š

```python
def _split_logits_by_stage(self, target_logits: torch.Tensor, 
                          draft_tokens: List[torch.Tensor], B: int, state) -> List[torch.Tensor]:
    """ä¿®å¤ç‰ˆæœ¬çš„logitsåˆ†å‰²"""
    if not draft_tokens:
        return []
    
    verbose = True  # è°ƒè¯•å¼€å…³
    if verbose:
        print(f"[SDVAR] Splitting logits: {target_logits.shape}")
    
    # 1. éªŒè¯CFGç»´åº¦
    expected_batch = 2 * B
    if target_logits.shape[0] != expected_batch:
        raise ValueError(f"Expected batch size {expected_batch}, got {target_logits.shape[0]}")
    
    # 2. è®¡ç®—æ­£ç¡®çš„èµ·å§‹ä½ç½®
    base_pos = 0
    if state.current_stage == 0:
        base_pos = self.target_model.first_l  # è·³è¿‡ç¬¬ä¸€å±‚
    else:
        base_pos = sum(p**2 for p in state.patch_nums[:state.current_stage])
    
    if verbose:
        print(f"[SDVAR] Base position: {base_pos}")
    
    # 3. åˆ†å‰²æ¯ä¸ªstageçš„logits
    logits_per_stage = []
    current_pos = base_pos
    
    for stage_idx, tokens in enumerate(draft_tokens):
        current_stage = state.current_stage + stage_idx
        pn = state.patch_nums[current_stage]
        stage_length = pn * pn
        
        # æ£€æŸ¥è¾¹ç•Œ
        if current_pos + stage_length > target_logits.shape[1]:
            if verbose:
                print(f"[SDVAR] Warning: Stage {current_stage} exceeds logits length")
            break
        
        # æå–è¿™ä¸ªstageçš„logits
        stage_logits = target_logits[:, current_pos:current_pos + stage_length, :]
        logits_per_stage.append(stage_logits)
        
        if verbose:
            print(f"[SDVAR] Stage {current_stage} logits: {stage_logits.shape}")
        
        current_pos += stage_length
    
    return logits_per_stage
```

### æµ‹è¯•ç¬¬äºŒæ­¥ä¿®å¤
```python
# æµ‹è¯•logitsåˆ†å‰²
result = tester.test_split_logits_by_stage(B=2, gamma=2)
print("åˆ†å‰²ä¿®å¤ç»“æœ:", result)
```

---

## ğŸ› ï¸ ç¬¬ä¸‰æ­¥ï¼šä¿®å¤çŠ¶æ€æ›´æ–°é€»è¾‘

### é—®é¢˜åˆ†æ
å½“å‰`update_state_with_accepted_tokens`å‡½æ•°å’Œä¸»å¾ªç¯éƒ½åœ¨æ›´æ–°f_hatï¼Œå¯¼è‡´ä¸ä¸€è‡´ã€‚

### ä¿®å¤æ–¹æ¡ˆ
ä¿®æ”¹ä¸»å‡½æ•°`sdvar_autoregressive_infer_cfg_parallel_v1`ä¸­çš„çŠ¶æ€æ›´æ–°éƒ¨åˆ†ï¼š

```python
# åœ¨ä¸»å‡½æ•°ä¸­æ‰¾åˆ°è¿™ä¸ªéƒ¨åˆ†ï¼ˆçº¦ç¬¬1520è¡Œé™„è¿‘ï¼‰
# 4. æ›´æ–°æ¨ç†çŠ¶æ€
if accept_length > 0:
    # æ³¨é‡Šæ‰è¿™è¡Œï¼Œé¿å…åŒé‡æ›´æ–°
    # self.update_state_with_accepted_tokens(draft_tokens, accept_length, state, B)
    
    # ç›´æ¥åœ¨è¿™é‡Œæ›´æ–°çŠ¶æ€
    for stage_idx in range(accept_length):
        current_stage = state.current_stage + stage_idx
        pn = state.patch_nums[current_stage]
        
        # è·å–è¿™ä¸€å±‚çš„tokens
        stage_tokens = draft_tokens[stage_idx]
        
        # è½¬æ¢å¹¶æ›´æ–°f_hat
        h_BChw = self.draft_model.vae_quant_proxy[0].embedding(stage_tokens)
        h_BChw = h_BChw.transpose(1, 2).reshape(B, self.draft_model.Cvae, pn, pn)
        
        # åŒæ—¶æ›´æ–°draftå’Œtargetçš„f_hat
        state.draft_f_hat, _ = self.draft_model.vae_quant_proxy[0].get_next_autoregressive_input(
            current_stage, state.total_stages, state.draft_f_hat, h_BChw
        )
        state.target_f_hat = state.draft_f_hat.clone()  # ä¿æŒåŒæ­¥
    
    if verbose:
        print(f"[SDVAR] Successfully processed {accept_length} stages")
```

---

## ğŸ› ï¸ ç¬¬å››æ­¥ï¼šå®Œæ•´åŠŸèƒ½æµ‹è¯•

### è¿è¡Œå®Œæ•´æµ‹è¯•
```python
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
results = tester.run_all_tests(B=2, gamma=2)

# åˆ†æç»“æœ
passed_tests = [r for r in results if r.passed]
failed_tests = [r for r in results if not r.passed]

print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
print(f"âœ… é€šè¿‡: {len(passed_tests)}")
print(f"âŒ å¤±è´¥: {len(failed_tests)}")

if failed_tests:
    print(f"\nğŸ” å¤±è´¥çš„æµ‹è¯•:")
    for test in failed_tests:
        print(f"- {test.test_name}: {test.message}")
```

### ç«¯åˆ°ç«¯æµ‹è¯•
```python
# æµ‹è¯•å®é™…æ¨ç†
try:
    print("ğŸ§ª ç«¯åˆ°ç«¯æ¨ç†æµ‹è¯•")
    result_img = sdvar_model.sdvar_autoregressive_infer_cfg_parallel_v1(
        B=1,
        label_B=torch.tensor([980]),  # volcano class
        gamma=2,
        cfg=1.5,
        verbose=True
    )
    print(f"âœ… æ¨ç†æˆåŠŸ! è¾“å‡ºå½¢çŠ¶: {result_img.shape}")
    
    # ä¿å­˜ç»“æœå›¾åƒ
    from torchvision.utils import save_image
    save_image(result_img, 'sdvar_parallel_v1_test.png')
    print("ğŸ–¼ï¸ å›¾åƒå·²ä¿å­˜ä¸º sdvar_parallel_v1_test.png")
    
except Exception as e:
    print(f"âŒ ç«¯åˆ°ç«¯æµ‹è¯•å¤±è´¥: {str(e)}")
    import traceback
    traceback.print_exc()
```

---

## ğŸ”§ è°ƒè¯•æŠ€å·§

### 1. å¯ç”¨è¯¦ç»†æ—¥å¿—
```python
# åœ¨æµ‹è¯•æ—¶å¯ç”¨verboseæ¨¡å¼
result_img = sdvar_model.sdvar_autoregressive_infer_cfg_parallel_v1(
    B=1, label_B=torch.tensor([980]), gamma=2, verbose=True
)
```

### 2. å½¢çŠ¶æ£€æŸ¥
```python
# åœ¨å…³é”®ä½ç½®æ·»åŠ å½¢çŠ¶æ£€æŸ¥
def debug_shapes(tensor, name):
    print(f"ğŸ” {name}: {tensor.shape} | device: {tensor.device} | dtype: {tensor.dtype}")

# åœ¨å‡½æ•°ä¸­ä½¿ç”¨
debug_shapes(combined_query, "combined_query")
debug_shapes(target_logits, "target_logits")
```

### 3. æ¯”è¾ƒwith test3
```python
# å¯¹æ¯”æ–°æ—§å®ç°çš„ç»“æœ
old_result = sdvar_model.sdvar_autoregressive_infer_cfg_sd_test3(
    B=1, label_B=torch.tensor([980]), entry_num=5, sd_mask=0
)
new_result = sdvar_model.sdvar_autoregressive_infer_cfg_parallel_v1(
    B=1, label_B=torch.tensor([980]), gamma=2
)

# è®¡ç®—å·®å¼‚
diff = torch.abs(old_result - new_result).mean()
print(f"å¹³å‡åƒç´ å·®å¼‚: {diff.item():.6f}")
```

---

## âœ… æˆåŠŸæ ‡å‡†

ä¿®å¤å®Œæˆåï¼Œä½ åº”è¯¥èƒ½çœ‹åˆ°ï¼š

1. **æµ‹è¯•é€šè¿‡**: æ‰€æœ‰å•å…ƒæµ‹è¯•éƒ½é€šè¿‡
2. **æ¨ç†æˆåŠŸ**: èƒ½å¤Ÿç”Ÿæˆå®Œæ•´çš„å›¾åƒ
3. **æ€§èƒ½æå‡**: Targetè°ƒç”¨æ¬¡æ•°å‡å°‘åˆ°2-5æ¬¡
4. **è´¨é‡ä¿æŒ**: ä¸test3å‡½æ•°ç»“æœç›¸ä¼¼ï¼ˆå·®å¼‚<0.01ï¼‰

---

## ğŸš€ ä¸‹ä¸€æ­¥è®¡åˆ’

å®ŒæˆåŸºç¡€ä¿®å¤åï¼ŒWeek 2å¯ä»¥å®ç°ï¼š
- åŠ¨æ€Î³è°ƒæ•´ç­–ç•¥
- é«˜çº§tokenåŒ¹é…ç®—æ³•
- æ›´å¤æ‚çš„æ³¨æ„åŠ›æ©ç 
- æ€§èƒ½ä¼˜åŒ–å’Œå†…å­˜ç®¡ç†

---

**ğŸ’¡ æç¤º**: ä¸€æ¬¡åªä¿®å¤ä¸€ä¸ªå‡½æ•°ï¼Œæ¯æ¬¡ä¿®å¤åéƒ½è¦æµ‹è¯•ï¼Œç¡®ä¿æ²¡æœ‰å¼•å…¥æ–°çš„é—®é¢˜ï¼ 

## ğŸ› ï¸ ä¿®å¤VARå¯¹æ¯”æµ‹è¯•

è¯·å°†Cell 9.5ä¸­çš„ä»£ç ä¿®æ”¹ä¸ºï¼š

```python
# ===================== CELL 9.5: VARåŸºçº¿å¯¹æ¯”æµ‹è¯• =====================
print("ğŸ” VARåŸºçº¿å¯¹æ¯”æµ‹è¯•")
print("="*50)

try:
    print("ğŸ§ª è¿è¡Œæ™®é€šVARæ¨ç†...")
    
    # ä½¿ç”¨sdvar_modelä¸­çš„target_modelè¿›è¡Œæ ‡å‡†VARæ¨ç†
    var_result = sdvar_model.target_model.autoregressive_infer_cfg(
        B=1,
        label_B=torch.tensor([980]).to('cuda'),  # ç›¸åŒçš„volcano classï¼Œç¡®ä¿åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
        cfg=1.5,
        g_seed=42  # å›ºå®šéšæœºç§å­ä»¥ä¾¿å¯¹æ¯”
    )
    
    print(f"âœ… VARæ¨ç†æˆåŠŸ!")
    print(f"ğŸ“Š VARè¾“å‡ºå½¢çŠ¶: {var_result.shape}")
    print(f"ğŸ“Š VARæ•°å€¼èŒƒå›´: [{var_result.min():.3f}, {var_result.max():.3f}]")
    
    # ä¿å­˜VARåŸºçº¿ç»“æœ
    from torchvision.utils import save_image
    save_image(var_result, 'var_baseline_test.png')
    print("ğŸ–¼ï¸ VARåŸºçº¿å›¾åƒå·²ä¿å­˜ä¸º var_baseline_test.png")
    
    # åŒæ—¶æ˜¾ç¤ºä¸¤ä¸ªç»“æœè¿›è¡Œå¯¹æ¯”
    from PIL import Image
    import matplotlib.pyplot as plt
    
    fig, axes = plt.subplots(1, 2, figsize=(16, 8))
    
    # VARåŸºçº¿ç»“æœ
    var_img = Image.open('var_baseline_test.png')
    axes[0].imshow(var_img)
    axes[0].set_title('VARåŸºçº¿ (æ ‡å‡†æ¨ç†)', fontsize=14)
    axes[0].axis('off')
    
    # SDVARç»“æœ
    try:
        sdvar_img = Image.open('sdvar_parallel_v1_test.png')
        axes[1].imshow(sdvar_img)
        axes[1].set_title('SDVAR Parallel v1.0', fontsize=14)
        axes[1].axis('off')
    except FileNotFoundError:
        axes[1].text(0.5, 0.5, 'SDVARå›¾åƒæœªæ‰¾åˆ°', ha='center', va='center')
        axes[1].set_title('SDVAR Parallel v1.0 (æœªç”Ÿæˆ)', fontsize=14)
        axes[1].axis('off')
    
    plt.tight_layout()
    plt.show()
    
    print("\nğŸ“Š å¯¹æ¯”åˆ†æ:")
    print(f"VARåŸºçº¿:  å½¢çŠ¶{var_result.shape}, èŒƒå›´[{var_result.min():.3f}, {var_result.max():.3f}]")
    
    # å¦‚æœSDVARç»“æœå­˜åœ¨ï¼Œè¿›è¡Œæ•°å€¼å¯¹æ¯”
    try:
        # å‡è®¾sdvar_resultæ˜¯ä¹‹å‰å­˜å‚¨çš„ç»“æœ
        if 'result_img' in locals():
            print(f"SDVAR v1:  å½¢çŠ¶{result_img.shape}, èŒƒå›´[{result_img.min():.3f}, {result_img.max():.3f}]")
            
            # è®¡ç®—L2è·ç¦»
            l2_distance = torch.norm(var_result - result_img).item()
            print(f"ğŸ” L2è·ç¦»: {l2_distance:.3f}")
            
            # è®¡ç®—ç›¸å…³æ€§
            correlation = torch.corrcoef(torch.stack([
                var_result.flatten(), 
                result_img.flatten()
            ]))[0, 1].item()
            print(f"ğŸ” åƒç´ ç›¸å…³æ€§: {correlation:.3f}")
        else:
            print("SDVARç»“æœä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œæ•°å€¼å¯¹æ¯”")
    except Exception as e:
        print(f"æ•°å€¼å¯¹æ¯”å¤±è´¥: {e}")
    
except Exception as e:
    print(f"âŒ VARå¯¹æ¯”æµ‹è¯•å¤±è´¥: {str(e)}")
    import traceback
    print("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
    traceback.print_exc()
    
    print("\nğŸ’¡ ä¿®å¤å»ºè®®:")
    print("1. ç¡®ä¿sdvar_modelå·²æ­£ç¡®åŠ è½½")
    print("2. æ£€æŸ¥target_modelæ˜¯å¦å¯è®¿é—®: sdvar_model.target_model")
    print("3. ç¡®ä¿æ ‡ç­¾tensoråœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š")
```

## ğŸš¨ æ ¹æœ¬åŸå› åˆ†æ

ä»ä»£ç å¯ä»¥çœ‹å‡ºï¼Œæˆ‘ä»¬åœ¨targetéªŒè¯æ—¶å¼€å¯äº†KV cacheï¼š

```python
# ç¡®ä¿KV cacheå¼€å¯
for blk in self.target_model.blocks:
    blk.attn.kv_caching(True)
```

**KV Cacheçš„å·¥ä½œæœºåˆ¶**ï¼š
- åœ¨è‡ªå›å½’ç”Ÿæˆä¸­ï¼ŒKV cacheä¼šç¼“å­˜ä¹‹å‰è®¡ç®—çš„keyå’Œvalue
- å½“cacheä¸ä¸ºç©ºæ—¶ï¼Œæ¨¡å‹å¯èƒ½åªå¯¹æ–°çš„tokenè®¡ç®—logits
- è¿™å°±è§£é‡Šäº†ä¸ºä»€ä¹ˆ6ä¸ªtokençš„è¾“å…¥åªäº§ç”Ÿäº†5ä¸ªtokençš„è¾“å‡ºï¼

## ğŸ› ï¸ è¯Šæ–­å’Œä¿®å¤æ–¹æ¡ˆ

è¯·åœ¨Colabä¸­æ·»åŠ ä»¥ä¸‹è¯Šæ–­ä»£ç æ¥éªŒè¯æˆ‘çš„åˆ†æï¼š

```python
# ===================== è¯Šæ–­ä»£ç  =====================
print("ğŸ” KV Cacheè¯Šæ–­")
print("="*50)

# æ£€æŸ¥targetæ¨¡å‹çš„KV cacheçŠ¶æ€
print("Targetæ¨¡å‹KV CacheçŠ¶æ€æ£€æŸ¥:")
for i, blk in enumerate(sdvar_model.target_model.blocks[:3]):  # åªæ£€æŸ¥å‰3ä¸ªblocks
    if hasattr(blk.attn, 'k_cache') and blk.attn.k_cache is not None:
        print(f"  Block {i}: KV cacheå­˜åœ¨, k_cache shape: {blk.attn.k_cache.shape}")
    else:
        print(f"  Block {i}: KV cacheä¸ºç©º")

# å…³é—­KV cacheåé‡æ–°æµ‹è¯•
print("\nğŸ”§ å¼ºåˆ¶æ¸…ç©ºKV cacheåé‡æ–°æµ‹è¯•...")
for blk in sdvar_model.target_model.blocks:
    blk.attn.kv_caching(False)
    # å¼ºåˆ¶æ¸…ç©ºcache
    if hasattr(blk.attn, 'k_cache'):
        blk.attn.k_cache = None
    if hasattr(blk.attn, 'v_cache'):
        blk.attn.v_cache = None

# é‡æ–°è¿è¡Œæµ‹è¯•
from sdvar_test_framework import SDVARParallelV1Tester
tester = SDVARParallelV1Tester(sdvar_model)
result = tester.test_split_logits_by_stage(B=1, gamma=2)
print("æ¸…ç©ºcacheåçš„æµ‹è¯•ç»“æœ:", result)
```

## ğŸ› ï¸ æ°¸ä¹…ä¿®å¤æ–¹æ¡ˆ

é—®é¢˜åœ¨äºæˆ‘ä»¬éœ€è¦åœ¨æ¯æ¬¡targetéªŒè¯å‰**å®Œå…¨é‡ç½®KV cache**ã€‚è¯·ä¿®æ”¹`target_verify_batch`å‡½æ•°ï¼š

```python
def target_verify_batch(self, draft_tokens: List[torch.Tensor], 
                       state, B: int) -> Tuple[List[torch.Tensor], int]:
    """targetæ¨¡å‹æ‰¹é‡éªŒè¯draftç”Ÿæˆçš„tokens"""
    if not draft_tokens:
        return [], 0
    
    gamma = len(draft_tokens)
    print(f"[SDVAR] Target verifying batch: gamma={gamma}, current_stage={state.current_stage}")
    
    # æ„å»ºè”åˆæŸ¥è¯¢åºåˆ—
    combined_query = self._build_combined_query(draft_tokens, state, B)
    print(f"[SDVAR] Combined query shape: {combined_query.shape}")
    
    # è®¡ç®—é€‚å½“çš„æ³¨æ„åŠ›æ©ç 
    mask_length = combined_query.shape[1]
    attn_bias = self._get_attention_mask(mask_length, state.current_stage, gamma)
    
    # ğŸ”§ å…³é”®ä¿®å¤ï¼šå®Œå…¨é‡ç½®KV cache
    for blk in self.target_model.blocks:
        blk.attn.kv_caching(False)  # å…ˆå…³é—­
        # å¼ºåˆ¶æ¸…ç©ºå·²æœ‰çš„cache
        if hasattr(blk.attn, 'k_cache'):
            blk.attn.k_cache = None
        if hasattr(blk.attn, 'v_cache'):
            blk.attn.v_cache = None
        # å†é‡æ–°å¼€å¯ï¼ˆè¿™æ ·ç¡®ä¿æ˜¯å¹²å‡€çš„çŠ¶æ€ï¼‰
        blk.attn.kv_caching(True)
    
    # targetå‰å‘è®¡ç®—
    state.target_calls += 1  # ç»Ÿè®¡è°ƒç”¨æ¬¡æ•°
    print(f"[SDVAR] Target forward call #{state.target_calls}")
    
    x = combined_query
    for blk in self.target_model.blocks:
        x = blk(x=x, cond_BD=state.target_cond_BD, attn_bias=attn_bias)
    
    target_logits = self.target_model.get_logits(x, state.target_cond_BD)
    print(f"[SDVAR] After target forward: logits shape {target_logits.shape}")
    
    # åˆ†å‰²logitså›å¯¹åº”çš„å±‚
    logits_per_stage = self._split_logits_by_stage(target_logits, draft_tokens, B, state)
    
    # åº”ç”¨CFG
    cfg_logits = []
    for stage_idx, stage_logits in enumerate(logits_per_stage):
        current_stage = state.current_stage + stage_idx
        ratio = current_stage / self.target_model.num_stages_minus_1
        t = state.cfg * ratio
        cfg_stage_logits = (1 + t) * stage_logits[:B] - t * stage_logits[B:]
        cfg_logits.append(cfg_stage_logits)
    
    print(f"[SDVAR] Target verification completed, generated {len(cfg_logits)} stage logits")
    return cfg_logits, gamma
```

è¯·å…ˆè¿è¡Œè¯Šæ–­ä»£ç éªŒè¯æˆ‘çš„åˆ†ææ˜¯å¦æ­£ç¡®ï¼Œç„¶åæˆ‘ä»¬å¯ä»¥åº”ç”¨è¿™ä¸ªä¿®å¤æ–¹æ¡ˆã€‚ 

## ğŸ” KV Cacheè¯Šæ–­å’Œä¿®å¤æ–¹æ¡ˆ

è¯·å…ˆè¿è¡Œè¯Šæ–­ä»£ç éªŒè¯æˆ‘çš„åˆ†ææ˜¯å¦æ­£ç¡®ï¼Œç„¶åæˆ‘ä»¬å¯ä»¥åº”ç”¨è¿™ä¸ªä¿®å¤æ–¹æ¡ˆã€‚

## ğŸ” è¯¦ç»†CFGè¯Šæ–­

ä»æœ€æ–°çš„é”™è¯¯ä¿¡æ¯çœ‹ï¼Œé—®é¢˜å¯èƒ½åœ¨äºCFGå¤„ç†è¿‡ç¨‹ä¸­çš„tensorç»´åº¦ä¸åŒ¹é…ã€‚è¯·è¿è¡Œä»¥ä¸‹è¯¦ç»†è¯Šæ–­ï¼š

```python
# ===================== è¯¦ç»†CFGè¯Šæ–­ä»£ç  =====================
print("ğŸ” CFGå’ŒTensorç»´åº¦è¯Šæ–­")
print("="*50)

# æ‰‹åŠ¨æ„å»ºcombined queryæ¥è¿½è¸ªé—®é¢˜
from sdvar_test_framework import SDVARParallelV1Tester
tester = SDVARParallelV1Tester(sdvar_model)

# åˆå§‹åŒ–state
state = sdvar_model._initialize_inference_state(B=1, label_B=torch.tensor([980]), g_seed=42, cfg=1.5, gamma=2)
print(f"åˆå§‹åŒ–å®Œæˆï¼Œstate.target_cond_BD shape: {state.target_cond_BD.shape}")

# ç”Ÿæˆdraft tokens  
draft_tokens = sdvar_model.draft_generate_batch(state, B=1, verbose=False)
print(f"Draft tokensç”Ÿæˆå®Œæˆ: {len(draft_tokens)} stages")
for i, tokens in enumerate(draft_tokens):
    print(f"  Stage {i}: {tokens.shape}")

# æ‰‹åŠ¨æ„å»ºcombined queryå¹¶è·Ÿè¸ªæ¯ä¸€æ­¥
print("\nğŸ” æ‰‹åŠ¨æ„å»ºCombined Queryè¿‡ç¨‹:")
try:
    # è°ƒç”¨_build_combined_queryå¹¶æ•è·å¯èƒ½çš„é”™è¯¯
    combined_query = sdvar_model._build_combined_query(draft_tokens, state, B=1)
    print(f"âœ… Combined queryæ„å»ºæˆåŠŸ: {combined_query.shape}")
    
    # æ£€æŸ¥stateä¸­ç›¸å…³å˜é‡çš„å½¢çŠ¶
    print(f"state.target_cond_BD shape: {state.target_cond_BD.shape}")
    print(f"state.target_lvl_pos shape: {state.target_lvl_pos.shape}")
    
    # æ‰‹åŠ¨æ‰§è¡Œtarget forwardè¿‡ç¨‹
    print("\nğŸ” Target Forwardè¿‡ç¨‹è¯Šæ–­:")
    
    # é‡ç½®KV cache
    for blk in sdvar_model.target_model.blocks:
        blk.attn.kv_caching(False)
        blk.attn.kv_caching(True)
    
    print(f"è¾“å…¥åˆ°targetæ¨¡å‹: {combined_query.shape}")
    
    # æ‰§è¡Œtarget forward
    x = combined_query
    print(f"åˆå§‹x: {x.shape}")
    
    # é€ä¸ªblockæ£€æŸ¥
    for i, blk in enumerate(sdvar_model.target_model.blocks[:3]):  # åªæ£€æŸ¥å‰3ä¸ª
        try:
            x_before = x.shape
            x = blk(x=x, cond_BD=state.target_cond_BD, attn_bias=None)
            print(f"Block {i}: {x_before} -> {x.shape}")
        except Exception as e:
            print(f"âŒ Block {i} å¤±è´¥: {str(e)}")
            break
    
    # æ£€æŸ¥get_logits
    try:
        logits = sdvar_model.target_model.get_logits(x, state.target_cond_BD)
        print(f"âœ… get_logitsæˆåŠŸ: {logits.shape}")
    except Exception as e:
        print(f"âŒ get_logitså¤±è´¥: {str(e)}")
        print(f"x shape: {x.shape}")
        print(f"cond_BD shape: {state.target_cond_BD.shape}")
        
except Exception as e:
    print(f"âŒ Combined queryæ„å»ºå¤±è´¥: {str(e)}")
    import traceback
    traceback.print_exc()
```

## ğŸ› ï¸ CFGç»´åº¦ä¿®å¤æ–¹æ¡ˆ

åŸºäºè¯Šæ–­ç»“æœï¼Œé—®é¢˜å¯èƒ½åœ¨äº`target_cond_BD`çš„ç»´åº¦å¤„ç†ã€‚è¯·æ£€æŸ¥ä»¥ä¸‹ä¿®å¤ï¼š

```python
def _build_combined_query(self, draft_tokens: List[torch.Tensor], 
                        state, B: int) -> torch.Tensor:
    """ä¿®å¤ç‰ˆæœ¬çš„combined queryæ„å»º - å¤„ç†CFGç»´åº¦é—®é¢˜"""
    if not draft_tokens:
        return torch.empty(2 * B, 0, 1920, device=state.draft_f_hat.device)
    
    verbose = True  # è°ƒè¯•å¼€å…³
    if verbose:
        print(f"[SDVAR] Building combined query for {len(draft_tokens)} stages")
        print(f"[SDVAR] Input B={B}, state.target_cond_BD.shape={state.target_cond_BD.shape}")
    
    # 1. æ­£ç¡®è®¡ç®—ä½ç½®åç§»
    base_pos = sum(p**2 for p in state.patch_nums[:state.current_stage])
    if verbose:
        print(f"[SDVAR] Base position: {base_pos}, current_stage: {state.current_stage}")
    
    # 2. æ„å»ºå®Œæ•´è¾“å…¥åºåˆ—
    all_embeddings = []
    
    # 3. å¦‚æœæ˜¯ç¬¬ä¸€é˜¶æ®µï¼Œéœ€è¦æ·»åŠ first_token_map
    if state.current_stage == 0:
        # è·å–ç¬¬ä¸€å±‚çš„token map
        first_l = self.target_model.first_l
        
        # ğŸ”§ å…³é”®ä¿®å¤ï¼šç¡®ä¿sosåªå–å‰Bä¸ªï¼Œé¿å…CFG doublingé—®é¢˜
        sos = state.target_cond_BD[:B]  # åªå–å‰Bä¸ªï¼Œä¸è¦CFG doublingçš„éƒ¨åˆ†
        if verbose:
            print(f"[SDVAR] sos shape after slicing: {sos.shape}")
        
        first_token_map = (
            sos.unsqueeze(1).expand(B, first_l, -1) +
            self.target_model.pos_start.expand(B, first_l, -1) +
            state.target_lvl_pos[:1, :first_l].expand(B, -1, -1)
        )
        all_embeddings.append(first_token_map)
        current_pos = first_l
        
        if verbose:
            print(f"[SDVAR] Added first_token_map: {first_token_map.shape}")
    else:
        current_pos = base_pos
        # TODO: æ·»åŠ ä¹‹å‰å·²æ¥å—çš„tokens (Week 2åŠŸèƒ½)
        if verbose:
            print(f"[SDVAR] Skipping first layer, starting from position: {current_pos}")
    
    # 4. å¤„ç†æ¯ä¸ªdraft token stage
    for stage_idx, tokens in enumerate(draft_tokens):
        current_stage = state.current_stage + stage_idx
        pn = state.patch_nums[current_stage]
        
        if verbose:
            print(f"[SDVAR] Processing stage {current_stage}, tokens: {tokens.shape}, pn: {pn}")
        
        # æ­£ç¡®çš„embeddingè·¯å¾„ï¼štokens -> VAE embedding -> word embedding
        vae_embedding = self.target_model.vae_quant_proxy[0].embedding(tokens)  # (B, pn*pn, Cvae)
        stage_embedding = self.target_model.word_embed(vae_embedding)  # (B, pn*pn, C)
        
        # æ·»åŠ ä½ç½®ç¼–ç 
        pos_embed = state.target_lvl_pos[:1, current_pos:current_pos + pn*pn].expand(B, -1, -1)
        stage_embedding = stage_embedding + pos_embed
        
        all_embeddings.append(stage_embedding)
        current_pos += pn * pn
        
        if verbose:
            print(f"[SDVAR] Stage {current_stage} embedding: {stage_embedding.shape}")
    
    # 5. æ‹¼æ¥æ‰€æœ‰embeddingså¹¶è¿›è¡ŒCFG doubling
    combined = torch.cat(all_embeddings, dim=1)  # B, total_tokens, C
    combined = combined.repeat(2, 1, 1)  # CFG doubling -> 2B, total_tokens, C
    
    if verbose:
        print(f"[SDVAR] Final combined query: {combined.shape}")
    
    return combined
``` 